import os
import sys
import argparse
from datetime import datetime

os.environ["VLLM_WORKER_MULTIPROC_METHOD"] = "spawn"  # è®¾ç½®å¤šè¿›ç¨‹å¯åŠ¨æ–¹å¼ï¼Œé˜²æ­¢ vLLM å†²çª

# æ·»åŠ é¡¹ç›®è·¯å¾„
flashrag_path = '/data/wyh/MedicalRAG/FlashRAG'
sys.path.insert(0, flashrag_path)

from flashrag.config import Config
from flashrag.utils import get_dataset
from flashrag.pipeline import SequentialPipeline
from flashrag.prompt import PromptTemplate

# ================= 1. Prompt å®šä¹‰åŒºåŸŸ =================
# ç­–ç•¥ A: Baseline (æ—  RAG)
# é‡ç‚¹ï¼šå¼ºè°ƒåˆ©ç”¨å†…éƒ¨çŸ¥è¯†ï¼Œä¸æåŠæ£€ç´¢ï¼Œä¸æåŠå‚è€ƒæ¡ˆä¾‹
BASELINE_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„åŒ»å­¦ä¸“å®¶åŠ©æ‰‹ã€‚è¯·åˆ©ç”¨ä½ æ‰€æŒæ¡çš„ä¸“ä¸šåŒ»å­¦çŸ¥è¯†æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
"""

# ç­–ç•¥ B: Strict RAG (ä¸¥æ ¼æ£€ç´¢)
# é‡ç‚¹ï¼šå¼ºåˆ¶ä¾èµ–æ£€ç´¢ç»“æœï¼Œå¦‚æœæ£€ç´¢ç»“æœæ— å…³åˆ™æ‹’ç­”
STRICT_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„åŒ»å­¦ä¸“å®¶åŠ©æ‰‹ã€‚ä¸ºäº†å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œç³»ç»Ÿæ£€ç´¢äº†æ•°æ®åº“ä¸­ç›¸ä¼¼çš„å†å²é—®ç­”ï¼ˆReference Casesï¼‰ä¾›ä½ å‚è€ƒã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œå›ç­”ï¼š
1. **åˆ†æå‚è€ƒæ¡ˆä¾‹**ï¼šä»”ç»†é˜…è¯»æä¾›çš„å†å²é—®ç­”ï¼Œå…³æ³¨ Questionï¼ˆç›¸ä¼¼é—®é¢˜ï¼‰å’Œ Answerï¼ˆä¸“å®¶è§£ç­”ï¼‰ã€‚
2. **æ ¸å¯¹ç–¾ç—…é¢†åŸŸ**ï¼šæ£€æŸ¥ Related_diseases å’Œ Labelï¼Œç¡®ä¿å‚è€ƒæ¡ˆä¾‹ä¸ç”¨æˆ·é—®é¢˜çš„ç–¾ç—…é¢†åŸŸä¸€è‡´ã€‚
3. **ç»¼åˆç”Ÿæˆ**ï¼šåŸºäºå‚è€ƒæ¡ˆä¾‹ä¸­çš„åŒ»å­¦çŸ¥è¯†ï¼Œé’ˆå¯¹ç”¨æˆ·çš„å…·ä½“é—®é¢˜ç”Ÿæˆå‡†ç¡®ã€é€šé¡ºçš„å›ç­”ã€‚

ã€æ³¨æ„ã€‘ï¼š
- å¦‚æœå‚è€ƒæ¡ˆä¾‹ä¸ç”¨æˆ·é—®é¢˜**å®Œå…¨æ— å…³**ï¼Œè¯·å¿½ç•¥è¯¥æ¡ˆä¾‹ã€‚
- å¦‚æœæ‰€æœ‰æ¡ˆä¾‹éƒ½æ— å…³ï¼Œè¯·è¯šå®å›ç­”â€œæ•°æ®åº“ä¸­æ²¡æœ‰ç›¸å…³å‚è€ƒä¿¡æ¯ï¼Œæ— æ³•å›ç­”â€ã€‚
- ä¸¥ç¦æ ¹æ®è®°å¿†ç¼–é€ è¯ç‰©å‰‚é‡æˆ–æ²»ç–—æ–¹æ¡ˆï¼Œå¿…é¡»åŸºäºå‚è€ƒä¿¡æ¯ã€‚

---
ã€å†å²å‚è€ƒæ¡ˆä¾‹ (Reference Cases)ã€‘:
{reference}
"""

# ç­–ç•¥ C: Hybrid RAG (æ··åˆç­–ç•¥)
# é‡ç‚¹ï¼šæ£€ç´¢ä¼˜å…ˆï¼Œä½†å…è®¸å®‰å…¨é™çº§åˆ°é€šç”¨å»ºè®®ï¼Œå…¼é¡¾å‡†ç¡®ç‡å’Œå›å¤ç‡
HYBRID_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„åŒ»å­¦ä¸“å®¶åŠ©æ‰‹ã€‚ç³»ç»Ÿæ£€ç´¢äº†éƒ¨åˆ†å†å²é—®ç­”ï¼ˆReference Casesï¼‰ä¾›ä½ å‚è€ƒã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰è¿›è¡Œå›ç­”ï¼š

Step 1: **ç›¸å…³æ€§è¯„ä¼°**
- ä»”ç»†é˜…è¯»ã€Reference Casesã€‘ï¼Œåˆ¤æ–­å®ƒä»¬æ˜¯å¦åŒ…å«èƒ½å›ç­”ç”¨æˆ·ã€User Questionã€‘çš„å…³é”®ä¿¡æ¯ã€‚
- å¦‚æœå‚è€ƒæ¡ˆä¾‹ä¸­çš„ç–¾ç—…ã€ç—‡çŠ¶æˆ–æ²»ç–—æ–¹æ¡ˆä¸ç”¨æˆ·é—®é¢˜é«˜åº¦ç›¸å…³ï¼Œæ ‡è®°ä¸º [å¼•ç”¨æ¨¡å¼]ã€‚
- å¦‚æœå‚è€ƒæ¡ˆä¾‹ä¸ç”¨æˆ·é—®é¢˜æ— å…³ï¼ˆå¦‚ç–¾ç—…é¢†åŸŸä¸åŒã€é—®é¢˜ç±»å‹ä¸åŒï¼‰ï¼Œæ ‡è®°ä¸º [é€šç”¨æ¨¡å¼]ã€‚

Step 2: **å›ç­”ç”Ÿæˆ**
- **å¦‚æœæ˜¯ [å¼•ç”¨æ¨¡å¼]**ï¼š
  - å¿…é¡»å®Œå…¨åŸºäºå‚è€ƒæ¡ˆä¾‹ä¸­çš„ä¿¡æ¯å›ç­”ã€‚
  - åœ¨å›ç­”æœ«å°¾æ³¨æ˜ï¼šâ€œï¼ˆä¾æ®æ£€ç´¢åˆ°çš„ç±»ä¼¼ç—…ä¾‹ï¼šCase Xï¼‰â€ã€‚
  
- **å¦‚æœæ˜¯ [é€šç”¨æ¨¡å¼]**ï¼š
  - å¿½ç•¥æ— å…³çš„å‚è€ƒæ¡ˆä¾‹ã€‚
  - åŸºäºä½ è‡ªèº«çš„åŒ»å­¦ä¸“ä¸šçŸ¥è¯†å›ç­”ã€‚
  - **å…³é”®çº¦æŸ**ï¼šå¿…é¡»åœ¨å›ç­”å¼€å¤´å£°æ˜ï¼šâ€œæ£€ç´¢åº“ä¸­æ— å®Œå…¨åŒ¹é…æ¡ˆä¾‹ï¼Œä»¥ä¸‹å»ºè®®åŸºäºé€šç”¨åŒ»å­¦çŸ¥è¯†ï¼Œä»…ä¾›å‚è€ƒã€‚â€
  - **å®‰å…¨çº¢çº¿**ï¼šåœ¨é€šç”¨æ¨¡å¼ä¸‹ï¼Œä¸¥ç¦æä¾›ç²¾ç¡®çš„å¤„æ–¹è¯å‰‚é‡ï¼Œåªèƒ½æä¾›æ²»ç–—åŸåˆ™æˆ–éå¤„æ–¹å»ºè®®ã€‚

---
ã€å†å²å‚è€ƒæ¡ˆä¾‹ (Reference Cases)ã€‘:
{reference}
"""

# é€šç”¨çš„ç”¨æˆ·è¾“å…¥æ¨¡æ¿
USER_PROMPT_TEMPLATE = """
ã€ç”¨æˆ·å½“å‰é—®é¢˜ (User Question)ã€‘: 
{question}

ã€ä½ çš„ä¸“å®¶å»ºè®®ã€‘:
"""

# ç­–ç•¥å­—å…¸æ˜ å°„
PROMPT_MAP = {
    "baseline": BASELINE_SYSTEM_PROMPT,
    "strict": STRICT_SYSTEM_PROMPT,
    "hybrid": HYBRID_SYSTEM_PROMPT
}

# ================= 2. ä¸»ç¨‹åºé€»è¾‘ =================

def main(args):
    # 1. ç¡®å®š Prompt å’Œ ä¿å­˜è·¯å¾„
    system_prompt = PROMPT_MAP[args.strategy]
    
    # ç»“æœä¿å­˜è·¯å¾„ï¼šoutput/{strategy}/
    base_save_dir = "/data/wyh/MedicalRAG/output"
    current_save_dir = os.path.join(base_save_dir, args.strategy)
    os.makedirs(current_save_dir, exist_ok=True)

    print(f"\n{'='*40}")
    print(f"ğŸš€ æ­£åœ¨å¯åŠ¨å®éªŒ: {args.strategy.upper()}")
    print(f"ğŸ“‚ ç»“æœä¿å­˜è·¯å¾„: {current_save_dir}")
    print(f"{'='*40}\n")

    # 2. æ„å»ºé…ç½®å­—å…¸
    config_dict = {
        "data_dir": "/data/wyh/MedicalRAG/data",
        "dataset_name": "Huatuo26M-Lite",
        "split": args.split,
        # "generator_model": ""
        # æ¡†æ¶ä¸è¯„æµ‹
        "framework": "host", 
        "metrics": ['gpt_score', 'gpt_hallucination_rate', 'gpt_harmful_rate'],
        
        "api_setting": {
            "model_name": "gpt-4o-mini",
            "concurrency": args.batch_size, # API å¹¶å‘æ•°
            "timeout_sec": 60,
            # "api_key": os.getenv("OPENAI_API_KEY")
        },

        # æ£€ç´¢é…ç½®
        # "index_path": "/data/wyh/MedicalRAG/data/indexes/huatuo_bm25_index/bm25",
        "index_path": "/data/wyh/MedicalRAG/data/indexes/huatuo_bge_index/bge_Flat.index",
        "corpus_path": "/data/wyh/MedicalRAG/data/indexes/corpus.jsonl",
        "retrieval_method": "bge",
        "retrieval_topk": 5,
        # "bm25_backend": "bm25s", # if and only if retrieval_method == bge

        # ç¡¬ä»¶é…ç½®
        "gpu_id": args.gpu_id,
        "gpu_num": len(args.gpu_id.split(',')),
        "gpu_memory_utilization": 0.8,
        
        # ä¿å­˜è·¯å¾„
        "save_dir": current_save_dir,
        
        # é‡è¦çš„ç”Ÿæˆå‚æ•°
        "generator_batch_size": args.batch_size,
        "generation_params": {
            "max_new_tokens": 512,
            "temperature": 0.1, # åŒ»å­¦é—®é¢˜ä¿æŒä½éšæœºæ€§
            "top_p": 0.9
        }
    }

    # 3. åˆå§‹åŒ– Config å’Œ Dataset
    config = Config("config.yaml", config_dict=config_dict)
    all_split = get_dataset(config)
    test_data = all_split[args.split]
    
    # Prompt
    template = PromptTemplate(
        config,
        system_prompt=system_prompt,
        user_prompt=USER_PROMPT_TEMPLATE
    )

    # Pipeline
    pipeline = SequentialPipeline(config, template)

    if args.strategy == "baseline":
        print(">>> æ­£åœ¨æ‰§è¡Œ Baseline æ¨¡å¼ (Naive Run - æ— æ£€ç´¢)...")
        result = pipeline.naive_run(test_data, do_eval=True)
    else:
        print(f">>> æ­£åœ¨æ‰§è¡Œ {args.strategy} RAG æ¨¡å¼ (Run - å«æ£€ç´¢)...")
        result = pipeline.run(test_data, do_eval=True)

    print(f"\nâœ… å®éªŒç»“æŸï¼ç»“æœå·²ä¿å­˜è‡³: {current_save_dir}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Medical RAG Experiment Runner")
    parser.add_argument("--strategy", type=str, required=True, 
                        choices=["baseline", "strict", "hybrid"],
                        help="é€‰æ‹©å®éªŒç­–ç•¥: baseline(æ— RAG), strict(ä¸¥æ ¼RAG), hybrid(æ··åˆRAG)")
    parser.add_argument("--gpu_id", type=str, default="0, 1", help="ä½¿ç”¨çš„ GPU IDï¼Œä¾‹å¦‚ '0,1'")
    parser.add_argument("--split", type=str, default="test", help="æµ‹è¯•é›†åˆ‡åˆ†åç§°")
    parser.add_argument("--batch_size", type=int, default=64, help="æ¨ç† Batch Size")
    
    args = parser.parse_args()

    main(args)
